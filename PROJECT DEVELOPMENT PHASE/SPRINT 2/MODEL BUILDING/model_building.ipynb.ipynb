{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing"
      ],
      "metadata": {
        "id": "kqumYYpSt5h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "V-gmqRSPvG_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,zoom_range=0.2)"
      ],
      "metadata": {
        "id": "P4bL5zHfvHDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "-1qvvvWDvHHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/ibm/Dataset/training_set\",target_size=(64,64),class_mode=\"categorical\",batch_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGhuQ4EyvHLr",
        "outputId": "ecb6ba17-09a0-4e6e-cd82-5d83904473aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5630 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_datagen.flow_from_directory(r\"/content/drive/MyDrive/ibm/Dataset/test_set\",target_size=(64,64),class_mode=\"categorical\",batch_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TBLb73yvHOv",
        "outputId": "5e66cb5a-7453-436e-bf7e-cbdee707644b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2243 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "WPyTfvzzvetE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "CTxjdQ9WveKZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "rXoqiw3hvis1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))"
      ],
      "metadata": {
        "id": "4eI_DT9Ovnvg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "metadata": {
        "id": "HvoH30fEvqG4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "IVzuZ2Dzvsjz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dense(9,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "mUaszq4AvsnA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
      ],
      "metadata": {
        "id": "cYRTEkzzvsqU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OST7wYgvvzvQ",
        "outputId": "0060566d-b073-47a4-ba2d-8ce355f93dea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,epochs=10,validation_data=x_test,steps_per_epoch=len(x_train)//10,validation_steps=len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8kZ-6g-v1sR",
        "outputId": "909d8cab-72aa-4b8f-ba28-e18a7d20b69d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 865s 50s/step - loss: 1.2491 - accuracy: 0.6500 - val_loss: 7.8053 - val_accuracy: 0.3156\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 158s 9s/step - loss: 0.3016 - accuracy: 0.8981 - val_loss: 7.9340 - val_accuracy: 0.4298\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 138s 8s/step - loss: 0.1461 - accuracy: 0.9556 - val_loss: 9.1657 - val_accuracy: 0.4365\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 122s 7s/step - loss: 0.0693 - accuracy: 0.9852 - val_loss: 10.4085 - val_accuracy: 0.4342\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 111s 6s/step - loss: 0.0458 - accuracy: 0.9870 - val_loss: 11.3407 - val_accuracy: 0.4360\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 110s 6s/step - loss: 0.0575 - accuracy: 0.9778 - val_loss: 11.7009 - val_accuracy: 0.4391\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 97s 5s/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 11.3881 - val_accuracy: 0.4374\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 86s 5s/step - loss: 0.0296 - accuracy: 0.9944 - val_loss: 11.9728 - val_accuracy: 0.4383\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 75s 4s/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 12.2790 - val_accuracy: 0.4391\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 66s 4s/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 12.4759 - val_accuracy: 0.4391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15fcb381d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"aslpng.h5\")"
      ],
      "metadata": {
        "id": "krRL_5oYv5a8"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}